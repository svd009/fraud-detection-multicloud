import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
import logging

class FraudDataPreprocessor:
    def __init__(self):
        self.scaler = RobustScaler()
        self.time_features = None
        
    def load_kaggle_data(self, filepath):
        """Load Kaggle credit card fraud dataset"""
        logging.info(f"Loading data from {filepath}")
        
        # Create 10-row sample data if file missing
        if not os.path.exists(filepath):
            sample_data = """Time,V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V23,V24,V25,V26,V27,V28,Amount,Class
0,-1.359807,-0.072081,2.536347,1.378155,-0.338321,0.462388,0.239599,0.098698,0.363787,0.090794,-0.551600,-0.617801,-0.991390,-0.311169,1.468177,-0.470401,0.207971,0.025791,0.403993,0.251412,-0.018307,0.277838,-0.110473,0.069069,-0.225775,-0.638672,0.101288,-0.339846,0.167170,100.50,0
1,1.191866,0.266151,0.166480,0.448154,0.060018,-0.082361,-0.078803,0.085102,-0.255425,-0.166974,1.612727,1.065235,0.489095,-0.143772,0.635558,0.463917,-0.114805,-0.183361,-0.145783,-0.069083,-0.225775,-0.638672,0.101288,-0.339846,0.167170,50.25,0
2,-1.715670,0.297364,0.625157,-1.689619,0.215721,-0.673689,0.990655,0.070218,-0.029879,0.325754,-0.806184,-0.641372,-1.214620,0.562368,-1.323488,-0.982050,-0.289042,-0.158731,-1.029917,-0.212219,-0.168484,1.179926,-0.158731,-0.876773,0.421965,-1.215179,-0.451566,-0.237686,123.45,0
3,0.451195,-0.166710,1.945915,0.324734,-0.371527,1.899062,0.279627,-0.834192,-0.364991,0.615238,1.945915,0.124878,-0.398998,-0.834192,0.324734,-0.371527,1.899062,0.279627,-0.834192,-0.364991,0.615238,1.945915,0.124878,-0.398998,-0.834192,0.324734,-0.371527,1.899062,78.90,0
4,-2.374412,1.126858,-1.398682,0.233614,-0.151437,-0.435276,0.102825,-0.196316,-0.811850,0.541524,-1.626649,-0.288736,-0.539938,-0.559526,-0.343986,-0.659849,-0.394011,-0.492881,-0.860199,-0.566784,-1.356616,-0.416966,-0.272562,-0.888628,0.562367,-0.211219,-0.288736,-0.539938,45.67,1
5,1.123456,-0.456789,0.789012,1.234567,-0.890123,0.456789,-0.123456,0.789012,-0.234567,0.890123,-0.456789,1.234567,-0.890123,0.456789,-1.234567,0.890123,-0.456789,1.234567,-0.890123,0.456789,-1.234567,0.890123,-0.456789,1.234567,-0.890123,0.456789,-1.234567,0.890123,200.00,0
6,-0.987654,2.345678,-1.234567,0.876543,-0.543210,1.987654,-0.654321,0.321098,-1.098765,0.765432,-0.432109,2.109876,-0.876543,1.543210,-0.109876,2.876543,-1.109876,0.765432,-0.432109,1.987654,-0.654321,0.321098,-1.098765,0.765432,-0.432109,1.987654,-0.654321,0.321098,150.75,0
7,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,300.25,0
8,-1.567890,0.345678,-1.890123,0.123456,-0.789012,1.567890,-0.345678,0.901234,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,0.890123,-0.567890,1.234567,-0.890123,0.567890,-1.234567,99.99,1
9,2.123456,-0.789012,1.456789,-0.234567,0.890123,-1.456789,0.234567,-0.890123,1.456789,-0.234567,0.890123,-1.456789,0.234567,-0.890123,1.456789,-0.234567,0.890123,-1.456789,0.234567,-0.890123,88.50,0"""
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w') as f:
                f.write(sample_data)
                print("✅ Created 10-row sample data for testing")
        
        df = pd.read_csv(filepath)
        print(f"Dataset shape: {df.shape}")
        print(f"Fraud cases: {df['Class'].sum()} ({df['Class'].mean():.2%})")
        return df
    
    def preprocess(self, df):
        """Handle class imbalance, scaling, feature engineering"""
        if len(df) < 5:
            print("⚠️ Sample data too small - using full dataset")
            X = df.drop('Class', axis=1)
            y = df['Class']
            self.scaler.fit(X[['Time', 'Amount']])
            return (X, X, y, y)
        
        X = df.drop('Class', axis=1)
        y = df['Class']
        
        time_amount = X[['Time', 'Amount']].copy()
        X_scaled = X.drop(['Time', 'Amount'], axis=1)
        X_scaled[['Time', 'Amount']] = self.scaler.fit_transform(time_amount)
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        self.time_features = ['Time', 'Amount'] + [f'V{i}' for i in range(1,29)]
        return (X_train, X_val, y_train, y_val)
